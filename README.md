# ğŸ¦™ Chat with Doc - LLAMA 3.1

This is a Streamlit-based application that allows users to chat with their PDF documents using LangChain, FAISS, and the LLAMA 3.1 model.

## ğŸš€ Features
- Upload a PDF document and extract information via chat.
- Uses FAISS for vector-based retrieval.
- Employs LangChain with LLAMA 3.1 for responses.

## ğŸ›  Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/chat-with-doc-llama.git
cd chat-with-doc-llama
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Up Environment Variables
- Rename `.env.example` to `.env`
- Add your API key:
```
GROQ_API_KEY=your_groq_api_key_here
```

### 4ï¸âƒ£ Run the Application
```bash
streamlit run app.py
```

## ğŸ“œ License
This project is licensed under the MIT License.
